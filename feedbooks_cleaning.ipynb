{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Ready DB\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from scrapy.selector import Selector\n",
    "from sqlalchemy.sql import text as sa_text\n",
    "\n",
    "engine = create_engine('mysql+pymysql://root:@localhost/oerintegrationdb', echo=False)\n",
    "Base = declarative_base(engine)\n",
    "\n",
    "\n",
    "class Triple(Base):\n",
    "    __tablename__ = 'triple'\n",
    "    __table_args__ = {'autoload': True}\n",
    "\n",
    "# \n",
    "class CleanTriple(Base):\n",
    "    __tablename__ = 'cleantriple'\n",
    "    __table_args__ = {'autoload': True}\n",
    "\n",
    "metadata = Base.metadata\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "print(\"Ready DB\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Setting Db conection\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Cleaned\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "triples = session.query(Triple).filter(Triple.subject ==\"feedbooks\")\n",
    "#engine.execute(sa_text('''TRUNCATE TABLE cleantriple''').execution_options(autocommit=True))\n",
    "\n",
    "print(\"Cleaned\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Done!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "source_raw = \"feedbooks\"\n",
    "session.add(CleanTriple(subject_uri=\"http://es.feedbooks.com\" ,subject_id =source_raw, predicate=\"hasName\", object=\"Feedbooks\"))\n",
    "session.add(CleanTriple(subject_uri=\"http://es.feedbooks.com\" ,subject_id =source_raw, predicate=\"isA\", object=\"Site\"))\n",
    "session.add(CleanTriple(subject_uri=\"http://es.feedbooks.com\" ,subject_id =source_raw, predicate=\"hasSiteLink\", object=\"http://es.feedbooks.com\"))\n",
    "\n",
    "for triple in triples:\n",
    "    # print(triple.subject_uri=source ,subject_id )\n",
    "    body = triple.object\n",
    "    source = triple.source\n",
    "    # Setting name\n",
    "    name = Selector(text=body).xpath('//h1/text()').get()\n",
    "    name_triple =  name.replace(\" \", \"\")\n",
    "    name_triple =  name_triple.replace(\"/\", \"\")\n",
    "    name_triple =  name_triple.replace(\":\", \"\")\n",
    "    # print(name_triple)\n",
    "    session.add(CleanTriple(subject_uri=source ,subject_id =source_raw, predicate=\"hasBook\", object=name_triple))\n",
    "    session.add(CleanTriple(subject_uri=source ,subject_id =name_triple, predicate=\"hasTitle\", object=name))\n",
    "    # print(triple.source)\n",
    "    session.add(CleanTriple(subject_uri=source ,subject_id =name_triple, predicate=\"hasSourceLink\", object=triple.source))\n",
    "    session.add(CleanTriple(subject_uri=source ,subject_id =name_triple, predicate=\"materialType\", object=\"Book\"))\n",
    "    \n",
    "    author = Selector(text=body).xpath('//h2/em/a/text()').get()\n",
    "    # print(author)\n",
    "    session.add(CleanTriple(subject_uri=source ,subject_id =name_triple, predicate=\"hasAuthor\", object=author))\n",
    "    \n",
    "    link = Selector(text=body).xpath('//h3/a/@href').getall()\n",
    "    # print(link) \n",
    "    session.add(CleanTriple(subject_uri=source ,subject_id =name_triple, predicate=\"hasDownloadLink\", object=link[0])) \n",
    "    \n",
    "    about_aux = Selector(text=body).xpath(\"//div[@class='indent justify']/p/text()\").getall()\n",
    "    about = \"\"\n",
    "    for aux in about_aux:\n",
    "        about += aux\n",
    "    # print(about) \n",
    "    session.add(CleanTriple(subject_uri=source ,subject_id =name_triple, predicate=\"hasAbout\", object=about))\n",
    "    \n",
    "    \n",
    "    meta = Selector(text=body).xpath(\"//strong/..\").getall()\n",
    "    meta = meta[:len(meta)-5]\n",
    "    \n",
    "    for meta_iter in meta:\n",
    "        meta_class = Selector(text=meta_iter).xpath(\"//text()\").get()\n",
    "        # print(meta_class)\n",
    "        if meta_class == \"Language:\":\n",
    "            language = Selector(text=meta_iter).xpath(\"//a/text()\").get()\n",
    "            # print(language)\n",
    "            session.add(CleanTriple(subject_uri=source ,subject_id =name_triple, predicate=\"hasLanguage\", object=language))\n",
    "        elif meta_class == \"Published in:\":\n",
    "            publication_date = Selector(text=meta_iter).xpath(\"//a/text()\").get()\n",
    "            # print(publication_date)\n",
    "            session.add(CleanTriple(subject_uri=source ,subject_id =name_triple, predicate=\"hasPublicationDate\", object=publication_date))\n",
    "        elif meta_class == \"Word count:\":\n",
    "            word_count_aux = Selector(text=meta_iter).xpath(\"//p/text()\").get()\n",
    "            # print(word_count_aux)\n",
    "            word_count_aux =  word_count_aux.split(\"(\")\n",
    "            # print(word_count_aux)\n",
    "            word_count = word_count_aux[0].strip()\n",
    "            word_count = word_count[0:word_count.find(\" \")].replace(\",\",\"\")\n",
    "            # print(word_count)\n",
    "            session.add(CleanTriple(subject_uri=source ,subject_id =name_triple, predicate=\"hasNumberOfWords\", object=word_count))\n",
    "            time = int(list(filter(str.isdigit, word_count_aux[1]))[0])\n",
    "            # print(time)\n",
    "            session.add(CleanTriple(subject_uri=source ,subject_id =name_triple, predicate=\"hasNumberOfHours\", object=time))\n",
    "        elif meta_class == \"Source:\":\n",
    "             # print(meta_iter)\n",
    "             book_source = Selector(text=meta_iter).xpath(\"//a/@href\").get()\n",
    "             # print(book_source)\n",
    "             if book_source is not None:\n",
    "                session.add(CleanTriple(subject_uri=source ,subject_id =name_triple, predicate=\"hasBookSource\", object=book_source))\n",
    "        elif meta_class == \"Translator:\":\n",
    "             # print(meta_iter)\n",
    "             translator = Selector(text=meta_iter).xpath(\"//p/text()\").get()\n",
    "             # print(translator.strip())\n",
    "             session.add(CleanTriple(subject_uri=source ,subject_id =name_triple, predicate=\"hasTranslator\", object=translator.strip()))\n",
    "        else:\n",
    "             # print(triple.source)\n",
    "             # print(meta_iter)\n",
    "            meta_class = Selector(text=meta_iter).xpath(\"//p/strong/text()\").get()\n",
    "            # print(meta_class)\n",
    "            if meta_class == \"License:\":\n",
    "                 # print(meta_iter)\n",
    "                 license = Selector(text=meta_iter).xpath(\"//p/a/@href\").get()\n",
    "                 # print(license)\n",
    "                 session.add(CleanTriple(subject_uri=source ,subject_id =name_triple, predicate=\"hasLicense\", object=license))\n",
    "            # elif meta_class == \"Copyright:\":\n",
    "            #      print(meta_iter)\n",
    "            #      copyright = Selector(text=meta_iter).xpath(\"//p/text()\").get()\n",
    "            #      print(copyright)\n",
    "                 # link_copyright = Selector(text=meta_iter).xpath(\"//a\").get()\n",
    "                 # if link_copyright:\n",
    "                 #     print(link_copyright)\n",
    "                 # session.add(CleanTriple(subject_uri=source ,subject_id =name_triple, predicate=\"hasCopyright\", object=copyright))\n",
    "            \n",
    "    categories = Selector(text=body).xpath(\"//div[@class='span-15 prepend-top book_categories']/span/a/text()\").getall()\n",
    "    # print(categories)\n",
    "    if len(categories) > 0:\n",
    "        for cat in categories:\n",
    "            # print(cat)\n",
    "            session.add(CleanTriple(subject_uri=source ,subject_id =name_triple, predicate=\"hasCategory\", object=cat))\n",
    "    \n",
    "    image = Selector(text=body).xpath(\"//img[@class='cover book_page_cover']/@src\").get()\n",
    "    # print(image)\n",
    "    session.add(CleanTriple(subject_uri=source ,subject_id =name_triple, predicate=\"hasImageLink\", object=image))\n",
    "\n",
    "\n",
    "\n",
    "session.commit()\n",
    "\n",
    "print(\"Done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}